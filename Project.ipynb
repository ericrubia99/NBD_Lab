{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networking for Big Data - Project\n",
    "- Jonas Barth 2050678\n",
    "- Susanna Bravi 1916681\n",
    "- Eric Rubia Aguilera 2049558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T14:50:21.702821500Z",
     "start_time": "2023-06-14T14:50:20.109639300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pyshark\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import copy\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "#### 1. Extract general info from your trace using capinfos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!capinfos -A _00000_20190410070000.pcap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Time Evaluation between Sequential and Parallel reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the time taken to process `.pcap` file sequentially and parallely as a function of the number of packets in the `.pcap` file. This allows us to show how the processing time scales with the number of packets. We initially used the `pyshark` library, however since it proved to be too slow to allow for a fast turnaround, we decided to use the `scapy` library instead which offers a similar functionality to `pyshark` but with better speed. Each processing algorithm is timed once, using Python's `timeit` package.\n",
    "   \n",
    "The [read.py](read.py) script lets you time either a sequential or parallel algorithm for a single `.pcap` file. The results are stored in a `.feather` file.,\n",
    "\n",
    "We run the processing for the following number of packets:,\n",
    "\n",
    "* 10\n",
    "* 100\n",
    "* 1000\n",
    "* 10000\n",
    "* 100000\n",
    "* 1000000\n",
    "\n",
    "##### Sequential Processing,\n",
    "The sequential processing, opens the `.pcap` file, reads the packets one by one into domain objects, creates a dataframe, and closes the file.,\n",
    "\n",
    "##### Parallel Processing,\n",
    "The parallel processing algorithm first divides the given `.pcap` file into $n$ smaller `.pcap` files of $p$ packets each. Then, a maximum of $m$ processes are started in parallel, each of which processes a single `.pcap` file sequentially. The number of parallel processes is capped at the parameter $m$ as not to overwhelm the available computing resources.,\n",
    "\n",
    "#### Results,\n",
    "The sequential and parallel processing algorithms were run once for each `.pcap` file. The line plot below shows the processing time in seconds for the number of packets in the `.pcap` files. For files with a number of packets $\\le 10000$, the parallel and sequential reading takes more or less the same amount of time. For the largest file of $1000000$ packets, the parallel processing is much faster than the sequential processing.,\n",
    "\n",
    "With parallel processing, there is some overhead in splitting the original file and starting the processes, hence we can expect that the pay off of parallel processing to be insignificant for a small number of packets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we combine all the different measurement dataframes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_df = reduce(lambda a, b: pd.concat((a, b), axis=0, ignore_index=True), map(lambda df_path: pd.read_feather(df_path), glob.glob(\"data/timing_results/*.feather\")))\n",
    "parallel_times = timing_df[timing_df.read_type == 'parallel']\n",
    "sequential_times = timing_df[timing_df.read_type == 'sequential']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T11:40:04.490769700Z",
     "start_time": "2023-06-18T11:39:59.376873Z"
    }
   },
   "outputs": [],
   "source": [
    "n = parallel_times.shape[0]\n",
    "plt.plot(parallel_times.n_packets, parallel_times.time_s, label=\"Parallel\")\n",
    "plt.plot(sequential_times.n_packets, sequential_times.time_s, label=\"Sequential\")\n",
    "plt.xticks([10**i for i in range(1, n + 1)], [f\"$10^{i}$\" for i in range(1, n + 1)])\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of Packets\")\n",
    "plt.ylabel(\"Seconds\")\n",
    "plt.title(\"Sequential vs Parallel Processing of pcap Files\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extract the IP which generates the highest amount as sender traffic, evaluate the bit rate (0.1 sec) for the 6 IP addresses mostly used as endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832768"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = pd.read_feather(\"packets.feather\")\n",
    "len(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFrame.head()\n",
    "source = dataFrame.groupby([\"IP_SRC\"])\n",
    "len(source) #we have 4548 different sources\n",
    "# what is the source that sends more pckts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_couple = dataFrame.groupby([\"IP_SRC\"])[['length']].agg('sum')\n",
    "print(data_couple.sort_values(by=['length'], ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = data_couple.max()\n",
    "print(data_couple.loc[data_couple['length'] == int(max.iloc[0])])\n",
    "#so maybe the ip source that generates more traffic is 150.57.136.251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyTheSource = dataFrame[dataFrame[\"IP_SRC\"] == \"150.57.136.251\"]\n",
    "\n",
    "data_destination = onlyTheSource.groupby([\"IP_DST\"])[['length']].agg('sum').sort_values(by=['length'], ascending=False).head(6)\n",
    "\n",
    "data_6IPs = onlyTheSource.groupby([\"IP_DST\"])\n",
    "print(data_destination)\n",
    "\n",
    "rowlength = int(data_destination.shape[0]/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(dataFrame[\"length\"], x='length',\n",
    "                   nbins=15, \n",
    "                   title='Histogram of Packet Length',\n",
    "                   labels={'length':'Packet Length (Byte)'},\n",
    "                   opacity=0.8,\n",
    "                   log_y=False,\n",
    "                   color_discrete_sequence=['#2a9d8f'],\n",
    "                   text_auto=True,\n",
    "                   template='plotly_white',\n",
    "                   width=800, \n",
    "                   height=400)\n",
    "fig.update_layout(\n",
    "    yaxis_title_text='Frequency',\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    #margin=dict(l=20, r=20, t=20, b=20),\n",
    "    #paper_bgcolor=\"gray\"\n",
    ")\n",
    "fig.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitRate(data, step_sec = 0.1):\n",
    "    start = data.iloc[0][\"time\"]\n",
    "    finish = data.iloc[-1][\"time\"]\n",
    "    #print(\"Start: \",start)\n",
    "    #print(\"Finish: \",finish)\n",
    "    \n",
    "    \n",
    "    data[\"time\"] -= data.iloc[0][\"time\"]\n",
    "    start = data.iloc[0][\"time\"]\n",
    "    finish = data.iloc[-1][\"time\"]\n",
    "    \n",
    "    #print(\"Start: \",start)\n",
    "    #print(\"Finish: \",finish)\n",
    "    \n",
    "    step = finish/ step_sec\n",
    "    finish = start + step_sec\n",
    "    value = []\n",
    "    #print(step)\n",
    "    for i in range(int(step)):\n",
    "    \n",
    "        #From Byte to bit - selection of the time interval between the start and the end of a single time slot\n",
    "        val = np.sum(data[(data[\"time\"]>=start) & (data[\"time\"]<finish)][\"length\"]*8)\n",
    "        if not np.isnan(val):\n",
    "            value.append(val/step_sec)\n",
    "        start = finish \n",
    "        finish = start + step_sec\n",
    "        \n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20,12), \n",
    "                        nrows=2, ncols=rowlength,     \n",
    "                        gridspec_kw=dict(hspace=0.4)) \n",
    "#fig.tight_layout()\n",
    "targets = zip(data_destination.index, axs.flatten())\n",
    "for i, (key, ax) in enumerate(targets):\n",
    "    print(key)\n",
    "    #ax.plot(data_couple.get_group(key)[\"length\"])\n",
    "    ax.plot(bitRate(data_6IPs.get_group(key)),marker = \"o\")\n",
    "    ax.set_title(key)\n",
    "    ax.set_xlabel(\"T (sec)\")\n",
    "    ax.set_ylabel(\"bit/sec\")\n",
    "    #ax.set_yscale('log')\n",
    "fig.suptitle('TOP 6 IP Dst for 150.57.136.251', fontsize=16)\n",
    "#plt.savefig(\"TOP 6 IP Dst for MyIP\")\n",
    "plt.show()\n",
    "\n",
    "#If now the step in bit rate is 0.1 second, the label of the x axes remains in seconds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Top 5 Destination IP (received bytes) and Top 5 Source IP (sent bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_top5dest = dataFrame.groupby([\"IP_DST\"])[['length']].agg('sum').sort_values(by=['length'], ascending=False).head(5)\n",
    "data_top5dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_dest = px.bar(data_top5dest, y=data_top5dest.index[:], x = data_top5dest['length'][:]/1e3,\n",
    "                    title='Top 5 destinations',\n",
    "                    opacity=0.8,\n",
    "                    color_discrete_sequence=['#e5b769'],\n",
    "                    text_auto=True,\n",
    "                    template='plotly_white',\n",
    "                    width=800, \n",
    "                    height=400)\n",
    "bar_dest.update_layout(\n",
    "    yaxis_title_text ='Destinations',\n",
    "    xaxis_title_text ='Received Bytes')# gap between bars of adjacent location coordinates\n",
    "bar_dest.update_yaxes(tickfont_family=\"Arial Black\")\n",
    "bar_dest.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_top5source = data_couple.sort_values(by=['length'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_source = px.bar(data_top5source, y=data_top5source.index[:], x = data_top5source['length'][:]/1e3,\n",
    "                    title='Top 5 sources',\n",
    "                    opacity=0.8,\n",
    "                    color_discrete_sequence=['#86bbd8'],\n",
    "                    text_auto=True,\n",
    "                    template='plotly_white',\n",
    "                    width=800, \n",
    "                    height=400)\n",
    "bar_source.update_layout(\n",
    "    yaxis_title_text ='Sources',\n",
    "    xaxis_title_text ='Bytes Sent')\n",
    "bar_source.update_yaxes(tickfont_family=\"Arial Black\")\n",
    "bar_source.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate bitRate considering all the trace with 3 different sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_plot = px.line(dataFrame,\n",
    "              x=[ i*0.1 for i in range(1,len(list(map(lambda x: x/1e6, bitRate(dataFrame,0.1))))+1)],\n",
    "              y=list(map(lambda x: x/1e6, bitRate(dataFrame,0.1))),\n",
    "              template='plotly_white',\n",
    "              title='Total bit rate',\n",
    "              markers=True)\n",
    "bit_plot['data'][0]['showlegend'] = True\n",
    "bit_plot['data'][0]['name'] = '0.1 sec'\n",
    "bit_plot.add_scatter(x=[ i*0.4 for i in range(1,len(list(map(lambda x: x/1e6, bitRate(dataFrame,0.4))))+1)], \n",
    "                y=list(map(lambda x: x/1e6, bitRate(dataFrame,0.4))),name=\"0.4 sec\")\n",
    "bit_plot.add_scatter(x=[ i*0.8 for i in range(1,len(list(map(lambda x: x/1e6, bitRate(dataFrame,0.8))))+1)], \n",
    "                y=list(map(lambda x: x/1e6, bitRate(dataFrame,0.8))),name=\"0.8 sec\")\n",
    "bit_plot.update_layout(\n",
    "    yaxis_title_text ='Mbps',\n",
    "    xaxis_title_text ='Time(s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. GeoLocal Referenciation of the 5 sessions with the highest amount of traffic generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ip2geotools.databases.noncommercial import DbIpCity\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_infos(ip_src_list, ip_dst_list):\n",
    "\n",
    "  src_geo_info = []\n",
    "  dst_geo_info = []\n",
    "  i = 0\n",
    "\n",
    "  for j in range(len(ip_src_list)):\n",
    "    try:\n",
    "      src_response = DbIpCity.get(ip_src_list[j], api_key='free')\n",
    "      dst_response = DbIpCity.get(ip_dst_list[j], api_key='free')\n",
    "    except:\n",
    "      continue\n",
    "    if src_response.latitude == None or dst_response.latitude == None: \n",
    "      continue\n",
    "    i +=1\n",
    "    src_geo_info.append([src_response.latitude, src_response.longitude, src_response.region])\n",
    "    dst_geo_info.append([dst_response.latitude, dst_response.longitude, dst_response.region])\n",
    "    if i == 10: break\n",
    "\n",
    "  return src_geo_info, dst_geo_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_couple = copy.deepcopy(dataFrame)\n",
    "#Change your local IP with the one used to navigate on the Web\n",
    "#data_couple[\"IP_SRC\"]= data_couple[\"IP_SRC\"].replace({'192.168.43.28':'46.37.14.27'})\n",
    "#data_couple[\"IP_DST\"] = data_couple[\"IP_DST\"].replace({'192.168.43.28':'46.37.14.27'})\n",
    "df_srcdst = list(zip(data_couple.IP_SRC, data_couple.IP_DST))\n",
    "\n",
    "mostcommon_srcdst = Counter(df_srcdst).most_common(5)\n",
    "mostcommon_srcdst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_src = []\n",
    "list_dst = []\n",
    "\n",
    "for i in range(len(mostcommon_srcdst)):\n",
    "    list_src.append(mostcommon_srcdst[i][0][0]) #src pos 0\n",
    "    list_dst.append(mostcommon_srcdst[i][0][1]) #dst pos 1\n",
    "\n",
    "#src_geo, dst_geo = geo_infos(list(top_10_flows['ip_src']), list(top_10_flows['ip_dst']))\n",
    "\n",
    "#Sigle Couple\n",
    "#src_geo, dst_geo = geo_infos(['185.86.84.30'],['46.37.14.27'])\n",
    "#5 Couples\n",
    "src_geo, dst_geo = geo_infos(list_src, list_dst)\n",
    "\n",
    "src_geo = pd.DataFrame(src_geo, columns=['latitude', 'longitude', 'region'])\n",
    "dst_geo = pd.DataFrame(dst_geo, columns=['latitude', 'longitude', 'region'])\n",
    "\n",
    "print(\"Data:  \\n\")\n",
    "print(src_geo)\n",
    "print()\n",
    "print(dst_geo)\n",
    "print(\"\\n\")\n",
    "\n",
    "flow_map = folium.Map([0, 0], zoom_start=2, tiles='Stamen Terrain')\n",
    "\n",
    "for i in range(len(src_geo)):\n",
    "  folium.Marker([src_geo.loc[i][0], src_geo.loc[i][1]], popup='<i>Mt. Hood Meadows</i>', \n",
    "                icon=folium.Icon(color='green')).add_to(flow_map)\n",
    "  folium.Marker([dst_geo.loc[i][0], dst_geo.loc[i][1]], popup='<i>Mt. Hood Meadows</i>',  \n",
    "                icon=folium.Icon(color='red')).add_to(flow_map)\n",
    "  folium.PolyLine([(src_geo.loc[i][0], src_geo.loc[i][1]), (dst_geo.loc[i][0], dst_geo.loc[i][1])], \n",
    "                  color=\"blue\", weight=1.5, opacity=1).add_to(flow_map)\n",
    "\n",
    "#flow_map.save(folder_image +\"Map_top_5_flows.html\")\n",
    "#display(flow_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 10 Protocol mostly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_flows = dataFrame.groupby(['IP_SRC', 'IP_DST', 'Protocol', 'src_port', 'dst_port']).agg(tot_len = pd.NamedAgg(column = 'length', aggfunc = 'sum')).reset_index()\n",
    "print(grouped_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_flows.Protocol.value_counts().index #we have only 9 protocols??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_flows[\"Protocol\"] = grouped_flows[\"Protocol\"].replace({1:\"ICMP\",6:\"TCP\",17:\"UDP\",50:\"ESP\",4:\"IPv4\",47:\"GRE\",89:\"OSPFIGP\",97:\"ETHERIP\",103:\"PIM\"}) \n",
    "#like this util we do not found the name of the other protocols\n",
    "#found them in https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_protocol = px.bar(grouped_flows[\"Protocol\"], y=grouped_flows.Protocol.value_counts().index, x = grouped_flows.Protocol.value_counts().values,\n",
    "                    title='Top 9 Protocols used',\n",
    "                    opacity=0.8,\n",
    "                    color_discrete_sequence=['#2a9d8f'],\n",
    "                    text_auto=True,\n",
    "                    template='plotly_white',\n",
    "                    width=800, \n",
    "                    height=400)\n",
    "\n",
    "bar_protocol.update_layout(\n",
    "    yaxis_title_text ='Prtocols',\n",
    "    xaxis_title_text ='Count')\n",
    "bar_protocol.update_yaxes(tickfont_family=\"Arial Black\")\n",
    "bar_protocol.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Port Scanner evaluation (10 Ports mostly used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_scan (x, dic):\n",
    "    ''' scan through the ports and update the counter at each import file. \n",
    "    save only the info for the well-known ports '''\n",
    "    for port in x:\n",
    "        if pd.isnull(port) == False:\n",
    "            #Well-Known Ports\n",
    "            if int(port) < 1024:\n",
    "                if port not in dic.keys():\n",
    "                    dic[port] = 1\n",
    "                else:\n",
    "                    dic[port] += 1\n",
    "    return(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scanning port analysing pandasDataframe, both for source and destination ports\n",
    "source_ports = {}\n",
    "source_ports = port_scan(dataFrame[\"src_port\"], source_ports)\n",
    "dest_ports = {}\n",
    "dest_ports = port_scan(dataFrame[\"dst_port\"], dest_ports)\n",
    "\n",
    "pd.DataFrame.from_dict(source_ports, orient = 'index').to_json('./source_ports.json')\n",
    "pd.DataFrame.from_dict(dest_ports, orient = 'index').to_json('./dest_ports.json')\n",
    "\n",
    "sports = pd.read_json('./source_ports.json')\n",
    "dports = pd.read_json('./dest_ports.json')\n",
    "\n",
    "sports = sports.reset_index()\n",
    "dports = dports.reset_index()\n",
    "sports = sports.rename(columns = {'index':'port', 0:'count'})\n",
    "dports = dports.rename(columns = {'index':'port', 0:'count'})\n",
    "\n",
    "sports = sports.sort_values(by = 'count', ascending = False)\n",
    "dports = dports.sort_values(by = 'count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux=dataFrame[dataFrame['dst_port']==-1]\n",
    "aux=aux[aux['Protocol']==17]\n",
    "#aux\n",
    "\n",
    "# We observe that these pkts have a defult -1 for source and destination number since they seem to be related to\n",
    "#control rather than to messages, but there are some UDP pkts... weirddddddo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM ?\n",
    "dports.port.value_counts().index #who is -1 ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dports['port']=dports['port'].astype('string')\n",
    "dports_10 = dports.sort_values(by=['count'], ascending=False).head(10)\n",
    "dports_10[\"port\"] = dports_10[\"port\"].replace({443:\"443 - HTTPS\",80:\"80 - HTTP\",-1:\"-1 - ICMP\",53:\"53 - DNS\",873:\"873 - rsync\",993:\"993 - IMAP4\",22:\"22 -SSH\",161:\"161 - SNMP \",25:\"25 - SMTP\",123:\"123 - NTP\"}) \n",
    "#sports['port']=sports['port'].astype('string')\n",
    "sports_10 = sports.sort_values(by=['count'], ascending=False).head(10)\n",
    "sports_10[\"port\"] = sports_10[\"port\"].replace({443:\"443 - HTTPS\",80:\"80 - HTTP\",-1:\"-1 - ICMP\",53:\"53 - DNS\",873:\"873 - rsync\",993:\"993 - IMAP4\",22:\"22 -SSH\",161:\"161 - SNMP \",25:\"25 - SMTP\",123:\"123 - NTP\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_plot = px.bar(dports_10,x=dports_10['port'],y=dports_10['count'],text_auto=True,\n",
    "                    title='Top 10 Destination ports used',\n",
    "                    opacity=0.8,\n",
    "                    color_discrete_sequence=['#86bbd8'],\n",
    "                    template='plotly_white',\n",
    "                    width=800, \n",
    "                    height=400)\n",
    "'''\n",
    "port_plot.update_layout(\n",
    "    yaxis_title_text ='Ports',\n",
    "    xaxis_title_text ='Count')\n",
    "port_plot.update_xaxes(tickfont_family=\"Arial Black\")\n",
    "port_plot.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_plot = px.bar(sports_10,x=sports_10['port'],y=sports_10['count'],text_auto=True,\n",
    "                    title='Top 10 Source ports used',\n",
    "                    opacity=0.8,\n",
    "                    color_discrete_sequence=['#86bbd8'],\n",
    "                    template='plotly_white',\n",
    "                    width=800, \n",
    "                    height=400)\n",
    "'''\n",
    "sport_plot.update_layout(\n",
    "    yaxis_title_text ='Ports',\n",
    "    xaxis_title_text ='Count')\n",
    "sport_plot.update_xaxes(tickfont_family=\"Arial Black\")\n",
    "sport_plot.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe we prefer them together?\n",
    "fig = make_subplots(rows=1, cols=2,subplot_titles=(\"Destination Ports\", \"Source Ports\"),shared_yaxes=True)\n",
    "fig.add_trace(port_plot['data'][0], row=1, col=1)\n",
    "fig.add_trace(sport_plot['data'][0], row=1, col=2)\n",
    "fig.update_layout(\n",
    "    height=600, \n",
    "    width=1500,\n",
    "    title_text=\"10 most used ports\",\n",
    "    xaxis_title_text ='Ports',\n",
    "    yaxis_title_text ='Count')\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.update_xaxes(tickfont_family=\"Arial Black\")\n",
    "fig.update_xaxes(title_text=\"ports\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"count\", row=1, col=2)\n",
    "fig.update_traces(textfont_size=9, textangle=0, textposition=\"outside\", cliponaxis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. InterArrival Time boxplot between TCP and UDP Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "def InterArrivalTime(data):\n",
    "    val = np.array(data[\"time\"])\n",
    "    #Calculate the n-th discrete difference along the given axis\n",
    "    return np.diff(val)\n",
    "\n",
    "data_protocol = copy.deepcopy(dataFrame[dataFrame[\"Protocol\"].isin([6,17])])\n",
    "data_protocol[\"Protocol\"] = data_protocol[\"Protocol\"].replace({1:\"ICMP\",6:\"TCP\",17:\"UDP\"})\n",
    "\n",
    "print(Counter(data_protocol[\"Protocol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_len = px.box(data_protocol, y=\"length\", x='Protocol', color='Protocol', template='plotly_white',color_discrete_sequence=[ '#e5b769' ,'#2a9d8f'])\n",
    "#Seems like we have small pkts\n",
    "#From the histogram at the beginning of the document we can see that almost all the pkts are < 2000 byte\n",
    "#Let's try to do for only pkts of this size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_protocol_2000 = data_protocol[data_protocol[\"length\"]<= 2000]\n",
    "box_len_2000 = px.box(data_protocol_2000, y=\"length\", x='Protocol', color='Protocol',template='plotly_white',color_discrete_sequence=[ '#e5b769' ,'#2a9d8f'])\n",
    "# The TCP box is quite big so the interquantile range is large... so we have data that is quite variable\n",
    "# The UDP's box is smaller that the TCP one so here the variance is smaller and also the size of the pckts is smaller that the TCP. UDP also does not have pckts pf size bigger that 1500 byte while TCP has\n",
    "# a median equal to 1299 so the 50% of the pckts are bigger taht 1300 bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(np.array(data_protocol['length']),q=0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=4,subplot_titles=(\"Original data UDP\",\"Original data TCP\", \"Pckts whit length < 2000 bytes UDP\",\"Pckts whit length < 2000 bytes TCP\"))\n",
    "fig.add_trace(box_len['data'][0], row=1, col=1)\n",
    "fig.add_trace(box_len['data'][1], row=1, col=2)\n",
    "fig.add_trace(box_len_2000['data'][0], row=1, col=3)\n",
    "fig.add_trace(box_len_2000['data'][1], row=1, col=4)\n",
    "fig.update_layout(\n",
    "    height=600, \n",
    "    width=1500,\n",
    "    title_text=\"Packets length\")\n",
    "fig.update_layout(template='plotly_white',showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soloUDP = data_protocol[data_protocol[\"Protocol\"]=='UDP']\n",
    "np.max(np.array(soloUDP['length']))\n",
    "#no UDP pckts bigger than 1500 bytes.. \n",
    "#maybe we should know why from the theory? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inter arrival time\n",
    "tcp_data = data_protocol_2000[data_protocol_2000[\"Protocol\"]==\"TCP\"]\n",
    "udp_data = data_protocol_2000[data_protocol_2000[\"Protocol\"]==\"UDP\"]\n",
    "\n",
    "inteArr_TCP= []\n",
    "for elem in tcp_data.groupby(['IP_SRC', 'IP_DST', 'Protocol', 'src_port', 'dst_port']):\n",
    "    #groupby tuple (key,dataframe)\n",
    "    inteArr_TCP += InterArrivalTime(elem[1]).tolist()\n",
    "\n",
    "inteArr_UDP = []\n",
    "for elem in udp_data.groupby(['IP_SRC', 'IP_DST', 'Protocol', 'src_port', 'dst_port']):\n",
    "    inteArr_UDP += InterArrivalTime(elem[1]).tolist()\n",
    "\n",
    "\n",
    "val_ = inteArr_TCP + inteArr_UDP\n",
    "\n",
    "label_TCP = [ \"TCP\" for i in range(len(inteArr_TCP))]\n",
    "label_UDP =[ \"UDP\" for i in range(len(inteArr_UDP))]\n",
    "\n",
    "lab_ = label_TCP + label_UDP\n",
    "\n",
    "d = {'Protocol': lab_, 'IntArrTime': val_}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean InterArrivalTime TCP Session: %.4f\"% np.mean(np.array(inteArr_TCP)))\n",
    "print(\"Mean InterArrivalTime UDP Session: %.4f\"% np.mean(np.array(inteArr_UDP)))\n",
    "#the TCP interarrival time is smaller than the UDP\n",
    "#median?\n",
    "print(\"Median InterArrivalTime TCP Session: %.5f\"% np.median(np.array(inteArr_TCP)))\n",
    "print(\"Median InterArrivalTime UDP Session: %.5f\"% np.median(np.array(inteArr_UDP)))\n",
    "# 3rd quartile\n",
    "print(\"3rd quartile InterArrivalTime TCP Session: %.5f\"% np.quantile(np.array(inteArr_TCP),q=0.75))\n",
    "print(\"3rd quartile InterArrivalTime UDP Session: %.5f\"% np.quantile(np.array(inteArr_UDP),q=0.75))\n",
    "#After this make sense to plot it for values less that 0.00004 (median of TCP) seconds and 0.0009 (median of UDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"IntArrTime\"] <  0.0009]\n",
    "fig1 = px.box(df1, y=\"IntArrTime\", x='Protocol', color='Protocol', template='plotly_white',color_discrete_sequence=[ '#e5b769' ,'#2a9d8f'])\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df[\"IntArrTime\"] < 0.00004]\n",
    "fig2 = px.box(df2, y=\"IntArrTime\", x='Protocol', color='Protocol', template='plotly_white',color_discrete_sequence=[ '#e5b769' ,'#2a9d8f'])\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=4,subplot_titles=(\"UDP < 0.009 s\",\"TCP < 0.009 s\", \"UDP < 0.00004\",\"TCP < 0.00004\"))\n",
    "fig.add_trace(fig1['data'][0], row=1, col=1)\n",
    "fig.add_trace(fig1['data'][1], row=1, col=2)\n",
    "fig.add_trace(fig2['data'][0], row=1, col=3)\n",
    "fig.add_trace(fig2['data'][1], row=1, col=4)\n",
    "fig.update_layout(\n",
    "    height=600, \n",
    "    width=1500,\n",
    "    title_text=\"Interarrival time\",\n",
    "    yaxis_title_text='Time (s)')\n",
    "fig.update_layout(template='plotly_white',showlegend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Develope your own analysis (e.g. Topology of the network using networkx or evaluation about a variable such as TTL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from networkx.algorithms import approximation as apx\n",
    "random.seed(26111998) # COMPLEANNO DI MAVI <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dest_IPs,Source_IPs=list(dataFrame['IP_DST']),list(dataFrame['IP_SRC'])\n",
    "len(np.unique(Dest_IPs+Source_IPs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_udp=dataFrame[dataFrame['Protocol']==17]\n",
    "data_tcp=dataFrame[dataFrame['Protocol']==6]\n",
    "data_ICMP=dataFrame[dataFrame['Protocol']==1]\n",
    "data_transport=dataFrame[(dataFrame['Protocol']==17) | (dataFrame['Protocol']==6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dest_IPs_UDP,Source_IPs_UDP=list(data_udp['IP_DST']),list(data_udp['IP_SRC'])\n",
    "print(\"There are \",len(np.unique(Dest_IPs_UDP+Source_IPs_UDP)),\" nodes sending and receiving UDP pckts\")\n",
    "Dest_IPs_TCP,Source_IPs_TCP=list(data_tcp['IP_DST']),list(data_tcp['IP_SRC'])\n",
    "print(\"There are \",len(np.unique(Dest_IPs_TCP+Source_IPs_TCP)),\" nodes sending and receiving TCP pckts\")\n",
    "Dest_IPs_ICMP,Source_IPs_ICMP=list(data_ICMP['IP_DST']),list(data_ICMP['IP_SRC'])\n",
    "len(np.unique(Dest_IPs_ICMP+Source_IPs_ICMP))\n",
    "print(\"There are \",len(np.unique(Dest_IPs_ICMP+Source_IPs_ICMP)),\"nodes sending and receiving ICMP pckts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDP GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_udp = data_udp.groupby(['IP_SRC', 'IP_DST', 'src_port', 'dst_port']).first().reset_index()\n",
    "data_udp = data_udp[['IP_SRC', 'IP_DST', 'src_port', 'dst_port']]\n",
    "UDP=data_udp[['IP_SRC','IP_DST']]\n",
    "udp_count=dict(UDP.value_counts())\n",
    "l=[]\n",
    "for i in range(len(data_udp)):\n",
    "    l.append(udp_count[(data_udp.iloc[i]['IP_SRC'],data_udp.iloc[i]['IP_DST'])])\n",
    "data_udp['Num Flows']=l\n",
    "data_udp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_UDP=nx.DiGraph()\n",
    "\n",
    "for _,i in data_udp.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    if (node_a,node_b) in Graph_UDP.edges:\n",
    "        Graph_UDP.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'])]\n",
    "    else:\n",
    "        Graph_UDP.add_edge(node_a,node_b)\n",
    "        Graph_UDP.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_UDP.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Graph_UDP.get_edge_data(\"96.226.38.235\",\"131.137.9.254\")\n",
    "#np.unique([i[0] for i in Graph_UDP.get_edge_data(\"96.226.38.235\",\"131.137.9.254\")['List']])\n",
    "# Runnare per vedere un essempio dei attributi dell'arco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TCP GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tcp = data_tcp.groupby(['IP_SRC', 'IP_DST', 'src_port', 'dst_port']).first().reset_index()\n",
    "data_tcp = data_tcp[['IP_SRC', 'IP_DST', 'src_port', 'dst_port']]\n",
    "TCP=data_tcp[['IP_SRC','IP_DST']]\n",
    "tcp_count=dict(TCP.value_counts())\n",
    "l=[]\n",
    "for i in range(len(data_tcp)):\n",
    "    l.append(tcp_count[(data_tcp.iloc[i]['IP_SRC'],data_tcp.iloc[i]['IP_DST'])])\n",
    "data_tcp['Num Flows']=l\n",
    "#data_tcp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_TCP=nx.DiGraph()\n",
    "\n",
    "for _,i in data_tcp.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    if (node_a,node_b) in Graph_TCP.edges:\n",
    "        Graph_TCP.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'])]\n",
    "    else:\n",
    "        Graph_TCP.add_edge(node_a,node_b)\n",
    "        Graph_TCP.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_TCP.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph_TCP.get_edge_data(\"95.36.218.85\",\"202.9.24.18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICMP GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ICMP = data_ICMP.groupby(['IP_SRC', 'IP_DST', 'src_port', 'dst_port']).first().reset_index()\n",
    "data_ICMP = data_ICMP[['IP_SRC', 'IP_DST', 'src_port', 'dst_port']]\n",
    "ICMP=data_ICMP[['IP_SRC','IP_DST']]\n",
    "ICMP_count=dict(ICMP.value_counts())\n",
    "l=[]\n",
    "for i in range(len(data_ICMP)):\n",
    "    l.append(ICMP_count[(data_ICMP.iloc[i]['IP_SRC'],data_ICMP.iloc[i]['IP_DST'])])\n",
    "data_ICMP['Num Flows']=l\n",
    "data_ICMP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_ICMP=nx.DiGraph()\n",
    "\n",
    "for _,i in data_ICMP.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    if (node_a,node_b) in Graph_ICMP.edges:\n",
    "        Graph_ICMP.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'])]\n",
    "    else:\n",
    "        Graph_ICMP.add_edge(node_a,node_b)\n",
    "        #In this case we could simply go for a directed graph without attributes because the numflow is always 1 and the list is [-1,-1] for all\n",
    "        Graph_ICMP.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_ICMP.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_ICMP.get_edge_data(\"8.247.137.248\",\"203.122.132.249\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the topology of the 3 graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_UDP=data_udp.sample(400)\n",
    "sample_TCP=data_tcp.sample(400)\n",
    "sample_ICMP=data_ICMP.sample(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_subset_UDP=nx.DiGraph()\n",
    "\n",
    "for _,i in sample_UDP.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    if (node_a,node_b) in Graph_subset_UDP.edges:\n",
    "        Graph_subset_UDP.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'])]\n",
    "    else:\n",
    "        Graph_subset_UDP.add_edge(node_a,node_b)\n",
    "        Graph_subset_UDP.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_subset_UDP.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'])]\n",
    "\n",
    "Graph_subset_TCP=nx.DiGraph()\n",
    "\n",
    "for _,i in sample_TCP.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    if (node_a,node_b) in Graph_subset_TCP.edges:\n",
    "        Graph_subset_TCP.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'])]\n",
    "    else:\n",
    "        Graph_subset_TCP.add_edge(node_a,node_b)\n",
    "        Graph_subset_TCP.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_subset_TCP.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'])]\n",
    "\n",
    "Graph_subset_ICMP=nx.DiGraph()\n",
    "\n",
    "for _,i in sample_ICMP.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    if (node_a,node_b) in Graph_subset_ICMP.edges:\n",
    "        Graph_subset_ICMP.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'])]\n",
    "    else:\n",
    "        Graph_subset_ICMP.add_edge(node_a,node_b)\n",
    "        Graph_subset_ICMP.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_subset_ICMP.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('_mpl-gallery')\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,4))\n",
    "nx.draw(Graph_subset_UDP,node_size = 20, width = 0.5, node_color = '#2a9d8f', ax=axes[0])\n",
    "nx.draw(Graph_subset_TCP,node_size = 20, width = 0.5, node_color = '#2a9d8f', ax=axes[1])\n",
    "nx.draw(Graph_subset_ICMP,node_size = 20, width = 0.5, node_color = '#2a9d8f', ax=axes[2])\n",
    "\n",
    "axes[0].set_title(\"UDP sample Graph\")\n",
    "axes[1].set_title(\"TCP sample Graph\")\n",
    "axes[2].set_title(\"ICMP sample Graph\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this overview of the topology we have decided to put together the TCP and UDP packets since the graphs do seem to be very similar, while the ICMP graph has a particular topology with fewer sources and more destinations than the other two protocols. <br>\n",
    "This is beacause the ICMP protocol is used for troubleshooting, the sources want to know if the destinations are reacheable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transport GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, as we have just mentioned above we are going to build a single graph containing both the packets send using the TCP or UDP protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So let's merge them!\n",
    "data_transport = data_transport.groupby(['IP_SRC', 'IP_DST', 'src_port', 'dst_port',\"Protocol\"]).first().reset_index()\n",
    "data_transport = data_transport[['IP_SRC', 'IP_DST', 'src_port', 'dst_port',\"Protocol\"]]\n",
    "#data_transport=data_transport.groupby(['IP_SRC', 'IP_DST', 'src_port', 'dst_port',\"Protocol\"]).agg(tot_len = pd.NamedAgg(column = 'length', aggfunc = 'sum')).reset_index()\n",
    "#data_transport.drop('tot_len',axis=1,inplace=True)\n",
    "TR=data_transport[['IP_SRC','IP_DST']]\n",
    "tr_count=dict(TR.value_counts())\n",
    "l=[]\n",
    "for i in range(len(data_transport)):\n",
    "    l.append(tr_count[(data_transport.iloc[i]['IP_SRC'],data_transport.iloc[i]['IP_DST'])])\n",
    "data_transport['Num Flows']=l\n",
    "#data_transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the new graph for both TCP and UDP\n",
    "Graph_Transport=nx.DiGraph()\n",
    "prot={17:'UDP',6:'TCP'}\n",
    "for _,i in data_transport.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    p=prot[i.Protocol]\n",
    "    if (node_a,node_b) in Graph_Transport.edges:\n",
    "        Graph_Transport.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'],p)]\n",
    "    else:\n",
    "        Graph_Transport.add_edge(node_a,node_b)\n",
    "        Graph_Transport.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_Transport.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'],p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's observe a small sample of the graph obtained combining both UDP and TCP pkts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_sample = data_transport.sample(400)\n",
    "#transport_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(transport_sample.Protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_Subset_Transport=nx.DiGraph()\n",
    "prot={17:'UDP',6:'TCP'}\n",
    "for _,i in transport_sample.iterrows():\n",
    "    node_a=i['IP_SRC']\n",
    "    node_b=i['IP_DST']\n",
    "    p=prot[i.Protocol]\n",
    "    if (node_a,node_b) in Graph_Subset_Transport.edges:\n",
    "        Graph_Subset_Transport.edges[node_a,node_b]['List']+=[(i['src_port'],i['dst_port'],p)]\n",
    "    else:\n",
    "        Graph_Subset_Transport.add_edge(node_a,node_b)\n",
    "        Graph_Subset_Transport.edges[node_a,node_b]['Num Flow']=i['Num Flows']\n",
    "        Graph_Subset_Transport.edges[node_a,node_b]['List']=[(i['src_port'],i['dst_port'],p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "nx.draw(Graph_Subset_Transport,node_size = 20, width = 0.5, node_color = '#2a9d8f', font_size = 6,ax=ax)\n",
    "plt.title(\"Sample of the Transport Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have observed before, the overall topology is very similar to the two graphs that we saw before. Hence, we think that, in terms of the topological study, it makes more sense to study the entirety of the pkt that use TCP and UDP altogether. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_Subset_Transport.get_edge_data('150.57.136.251', '54.240.76.88')\n",
    "# Here we can observe how now every flow has both assigned the source and the destination port plus the protocol used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Metrics to obtain a better understanding of the Graphs' topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nodes we have?\n",
    "print(\"Number of nodes: %.0f\"% nx.number_of_nodes(Graph_ICMP))\n",
    "print(\"Number of edges: %.0f\"% nx.number_of_edges(Graph_ICMP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree of the two Graphs\n",
    "Counter(nx.degree_histogram(Graph_ICMP)) #almost all the nodes have degree 0\n",
    "\n",
    "plt.style.use('_mpl-gallery')\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.figure(figsize=(4, 4))\n",
    "#fig, axes = plt.subplots(1,2, figsize=(15,4))\n",
    "icmp_hist = plt.hist(np.log(list(nx.degree_centrality(Graph_ICMP).values())),bins=30,label='ICMP')\n",
    "transport_hist = plt.hist(np.log(list(nx.degree_centrality(Graph_Transport).values())),bins=30,label='Transport')\n",
    "plt.legend()\n",
    "plt.title(\"Degree in log-scale\")\n",
    "plt.show()\n",
    "# there are lot of nodes that are destination and have a degree centrality near 0.\n",
    "# Nonetheless there are very few nodes with higher degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean of the degree of the Transport Graph is %.6f\"% np.mean(list(nx.degree_centrality(Graph_Transport).values())),\"and the variance is %.6f\"% np.var(list(nx.degree_centrality(Graph_Transport).values())))\n",
    "print(\"The mean of the degree of the ICMP Graph is %.6f\"% np.mean(list(nx.degree_centrality(Graph_ICMP).values())),\"and the variance is %.6f\"% np.var(list(nx.degree_centrality(Graph_ICMP).values())))\n",
    "print()\n",
    "ratio = np.var(list(nx.degree_centrality(Graph_ICMP).values()))/np.var(list(nx.degree_centrality(Graph_Transport).values()))\n",
    "print(\"The ratio between the two variances is %.2f\"% ratio ) #strange ratio..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How many nodes we need to delete to have a disconnected graph?\", apx.node_connectivity(Graph_ICMP)) # The graph is not connected and we can not calculate algorithms like the longest path\n",
    "# Node connectivity is equal to the minimum number of nodes that must be removed to disconnect G or render it trivial. \n",
    "# By Mengerâ€™s theorem, this is equal to the number of node independent paths (paths that share no nodes other than source and target)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our graphs are disconnected and directed, in order to evaluate other metrics we construct the undirected versions of the two graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDIRECTED GRAPHS\n",
    "undirected_ICMP = nx.Graph()\n",
    "undirected_ICMP.add_edges_from(Graph_ICMP.edges())\n",
    "undirected_transport = nx.Graph()\n",
    "undirected_transport.add_edges_from(Graph_Transport.edges()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is the ICMP graph acyciclic?\", nx.is_directed_acyclic_graph(Graph_ICMP)) # so our graph have cycles and we can not do the longest path (also the other 2)\n",
    "print(\"Is the Transport graph acyciclic?\", nx.is_directed_acyclic_graph(Graph_Transport)) \n",
    "print(\"Are there some clusters in ICMP?\", apx.average_clustering(undirected_ICMP)) #no clutsers in ICMP\n",
    "print(\"Are there some clusters in Transport graph?\", apx.average_clustering(undirected_transport)) #neither for the transport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the number of different components\n",
    "print(\"Number of Connected Components of ICMP Graph is\", nx.number_connected_components(undirected_ICMP), \"and the number of connected components of the Transport Graph is\",nx.number_connected_components(undirected_transport))\n",
    "#ok, now we can look at the set of nodes in the connected graph containing the source that send more (from point 3)\n",
    "print(\"The set of nodes in the component of the ICMP Graph cointaing node 150.57.136.251 are\", nx.node_connected_component(undirected_ICMP,'150.57.136.251')) #only 4 nodes\n",
    "print(\"The cardinality of set of nodes in the component of the Transport Graph cointaing node 150.57.136.251 are\", len(nx.node_connected_component(undirected_transport,'150.57.136.251'))) #lot of nodes, let's display how many they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can look at the diameter of the components\n",
    "# In graph theory, the diameter of a connected component refers to the longest shortest path between any two nodes within that component. \n",
    "# In other words, it measures the maximum number of edges that must be traversed to go from one node to another within the component.\n",
    "component_diameter_ICMP = []\n",
    "for component in nx.connected_components(undirected_ICMP):\n",
    "    component_diameter_ICMP.append(nx.diameter(undirected_ICMP.subgraph(component)))\n",
    "\n",
    "# mmm, takes 1 minutes to run, I don't know if it is usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_diameter_T = []\n",
    "for component in nx.connected_components(undirected_transport):\n",
    "    component_diameter_T.append(nx.diameter(undirected_transport.subgraph(component)))\n",
    "# this takes 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the Bar Plot for both the ICMP and the Transport Diameters\n",
    "#ICMP\n",
    "ICMPx=list(range(min(component_diameter_ICMP),max(component_diameter_ICMP)+1))\n",
    "aux=dict(sorted(Counter(component_diameter_ICMP).items()))\n",
    "for i in ICMPx:\n",
    "    if i not in aux.keys():\n",
    "        aux[i]=0\n",
    "ICMPy=list(dict(sorted(aux.items())).values())\n",
    "\n",
    "#Transport\n",
    "Tx=list(range(min(component_diameter_T),max(component_diameter_T)+1))\n",
    "auxT=dict(sorted(Counter(component_diameter_T).items()))\n",
    "for i in Tx:\n",
    "    if i not in auxT.keys():\n",
    "        auxT[i]=0\n",
    "auxT[0]=0\n",
    "Tx.append(0)\n",
    "Tx=sorted(Tx)\n",
    "Ty=list(dict(sorted(auxT.items())).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3),sharey=False)\n",
    "\n",
    "# Bar Plot ICMP diameter nel primo subplot\n",
    "ax1.bar(ICMPx,ICMPy, label=\"ICMP diameter\")\n",
    "ax1.set_xlabel(\"Diameter\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.set_title(\"Frequencies of ICMP Component's Diameters\")\n",
    "\n",
    "# Bar Plot Transport diameter nel secondo subplot\n",
    "ax2.bar(Tx,Ty, label=\"Transport diameter\", color='orange')\n",
    "ax2.set_xlabel(\"Diameter\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "ax2.set_title(\"Frequencies of Transport Component's Diameters\")\n",
    "plt.xticks(range(len(Tx)), Tx)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import math, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Label DSCP\"] = pd.to_numeric(dataFrame[\"Label DSCP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSCP Occurrences: \n",
      "{'BE': 829966, 'NotKnown': 138, 'AF': 1172, 'EF': 1149, 'CS6': 343}\n"
     ]
    }
   ],
   "source": [
    "dscp_tab = {0: \"BE\",\n",
    "            8: \"Priority\",\n",
    "            10: \"Priority\",\n",
    "            12: \"Priority\",\n",
    "            14: \"Priority\",\n",
    "            16: \"Immediate\",\n",
    "            18: \"Immediate\",\n",
    "            20: \"Immediate\",\n",
    "            22: \"Immediate\",\n",
    "            24: \"Flash voice\",\n",
    "            26: \"Flash voice\",\n",
    "            28: \"Flash voice\",\n",
    "            30: \"Flash voice\",\n",
    "            32: \"Flash Override\",\n",
    "            34: \"Flash Override\",\n",
    "            36: \"Flash Override\",\n",
    "            38: \"Flash Override\",\n",
    "            40: \"Critical voice RTP\",\n",
    "            46: \"Critical voice RTP\",\n",
    "            48: \"Internetwork control\",\n",
    "            56: \"Network Control\"\n",
    "            } \n",
    "\n",
    "dataFrame = dataFrame.replace({'Label DSCP': dscp_tab})\n",
    "dataFrame = dataFrame.replace({'Label DSCP': {\"Priority\":\"AF\",\"Immediate\":\"AF\",\"Flash voice\":\"AF\",\n",
    "                                \"Flash Override\":\"AF\",\"Critical voice RTP\":\"EF\",\n",
    "                                 \"Internetwork control\":\"CS6\",\"Network Control\":\"CS6\",\n",
    "                                 4:\"NotKnown\",2:\"NotKnown\",6:\"NotKnown\",7:\"NotKnown\",\n",
    "                                 1:\"NotKnown\",41:\"EF\",42:\"EF\",43:\"EF\",44:\"EF\",45:\"EF\",49:\"NotKnown\",54:\"NotKnown\",11:\"NotKnown\",50:\"NotKnown\",29:\"NotKnown\"}})\n",
    "\n",
    "print(\"DSCP Occurrences: \")\n",
    "print(dict(Counter(dataFrame[\"Label DSCP\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20556/20556 [15:29<00:00, 22.12it/s]\n"
     ]
    }
   ],
   "source": [
    "data_unique = dataFrame.drop_duplicates([\"IP_DST\",\"dst_port\"])\n",
    "\n",
    "#all possible (IP_0,port_0)\n",
    "flows_list = data_unique[[\"IP_DST\",\"dst_port\"]].values.tolist()\n",
    "\n",
    "\n",
    "dict_rows = {}\n",
    "\n",
    "for i in tqdm(range(len(flows_list))):\n",
    "    #extract all packets received by each specific couple IP dst, port destination\n",
    "    subdata = dataFrame[(dataFrame[\"IP_DST\"] == flows_list[i][0]) & (dataFrame[\"dst_port\"] == flows_list[i][1])]\n",
    "    \n",
    "    #20 is just the length of our vector when we change the values in a logaritmic scale\n",
    "    #max 2**19 --> 524288 | This consideration depends on your dataset\n",
    "    length = np.zeros(21)\n",
    "    pkt = np.zeros(21)\n",
    "    \n",
    "    #At least 2 pkts received by this specific (IP_0,port_0)\n",
    "    if subdata.shape[0] >= 2:\n",
    "        \n",
    "        #Check about the label, we want to be sure to analyze a couple with just 1 DSCP\n",
    "        #The vector that represents this element will have just one label\n",
    "        \n",
    "        if Counter(subdata[\"Label DSCP\"] == 1):\n",
    "        \n",
    "            dtu = subdata.drop_duplicates([\"IP_SRC\",\"src_port\"])\n",
    "            \n",
    "            list_couple_src = dtu[[\"IP_SRC\",\"src_port\"]].values.tolist()\n",
    "            \n",
    "            for elem in list_couple_src:\n",
    "                #Observe each element in the Neighborhood (N)\n",
    "                finaldata = subdata[(subdata[\"IP_SRC\"]==elem[0]) & (subdata[\"src_port\"]==elem[1])]\n",
    "                \n",
    "                #Number of packets\n",
    "                #Ex: pck = 245, log_{2}(245) = 7.94 --> ceil()--> 8 \n",
    "                #The range considered is (2**7,2**8] = (128,256]\n",
    "                length[math.ceil(math.log(finaldata.shape[0])/math.log(2))] += 1\n",
    "                \n",
    "                #Packet length analysis --> Byte\n",
    "                #extract each packet length\n",
    "                for index,row in finaldata.iterrows():\n",
    "                    pkt[math.ceil(math.log(row[\"length\"])/math.log(2))] += 1\n",
    "                    \n",
    "            #Normalization vector both for packets and bytes    \n",
    "            dict_rows[(flows_list[i][0],flows_list[i][1])] = [list(Counter(subdata[\"Label DSCP\"]).keys())[0],length/sum(length),pkt/sum(pkt)]\n",
    "                \n",
    "        else:\n",
    "            #print(\"problem\")\n",
    "            break\n",
    "\n",
    "            \n",
    "#Save the data in a pickle file\n",
    "aux=pd.DataFrame.from_dict(dict_rows)\n",
    "pd.to_pickle(aux,'Flows.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>221.244.225.179</th>\n",
       "      <th>203.122.136.47</th>\n",
       "      <th>155.70.48.196</th>\n",
       "      <th>172.201.31.90</th>\n",
       "      <th>192.226.35.111</th>\n",
       "      <th>66.132.46.70</th>\n",
       "      <th>216.116.245.213</th>\n",
       "      <th>131.137.243.202</th>\n",
       "      <th>121.211.234.65</th>\n",
       "      <th>131.137.77.24</th>\n",
       "      <th>...</th>\n",
       "      <th>133.245.254.55</th>\n",
       "      <th>131.137.243.202</th>\n",
       "      <th>216.116.245.163</th>\n",
       "      <th>150.57.112.227</th>\n",
       "      <th>157.24.200.214</th>\n",
       "      <th>118.101.243.35</th>\n",
       "      <th>150.57.154.156</th>\n",
       "      <th>131.137.220.107</th>\n",
       "      <th>131.137.243.202</th>\n",
       "      <th>131.137.251.245</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>64918</th>\n",
       "      <th>80</th>\n",
       "      <th>27023</th>\n",
       "      <th>443</th>\n",
       "      <th>443</th>\n",
       "      <th>8878</th>\n",
       "      <th>443</th>\n",
       "      <th>52726</th>\n",
       "      <th>17010</th>\n",
       "      <th>24134</th>\n",
       "      <th>...</th>\n",
       "      <th>58270</th>\n",
       "      <th>55055</th>\n",
       "      <th>443</th>\n",
       "      <th>59234</th>\n",
       "      <th>443</th>\n",
       "      <th>60296</th>\n",
       "      <th>57659</th>\n",
       "      <th>52687</th>\n",
       "      <th>55108</th>\n",
       "      <th>51412</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>...</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.16666666666666666, 0.166666666666...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.25, 0.05, 0.05, 0.15, 0.15, 0.05, 0.0, 0.0,...</td>\n",
       "      <td>[0.02857142857142857, 0.14285714285714285, 0.1...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016190661226...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9983525535420...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0154854079809...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8948453608247...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001180219520...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0083880379285...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008012820512...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 5744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     221.244.225.179  \\\n",
       "                                               64918   \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016190661226...   \n",
       "\n",
       "                                      203.122.136.47  \\\n",
       "                                               80      \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 0.16666666666666666, 0.166666666666...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9983525535420...   \n",
       "\n",
       "                                       155.70.48.196  \\\n",
       "                                               27023   \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "\n",
       "                                       172.201.31.90  \\\n",
       "                                               443     \n",
       "0                                                 BE   \n",
       "1  [0.25, 0.05, 0.05, 0.15, 0.15, 0.05, 0.0, 0.0,...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0154854079809...   \n",
       "\n",
       "                                      192.226.35.111  \\\n",
       "                                               443     \n",
       "0                                                 BE   \n",
       "1  [0.02857142857142857, 0.14285714285714285, 0.1...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8948453608247...   \n",
       "\n",
       "                                        66.132.46.70  \\\n",
       "                                               8878    \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001180219520...   \n",
       "\n",
       "                                     216.116.245.213  \\\n",
       "                                               443     \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0083880379285...   \n",
       "\n",
       "                                     131.137.243.202  \\\n",
       "                                               52726   \n",
       "0                                                 BE   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, ...   \n",
       "\n",
       "                                      121.211.234.65  \\\n",
       "                                               17010   \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001...   \n",
       "\n",
       "                                       131.137.77.24  ...  \\\n",
       "                                               24134  ...   \n",
       "0                                                 BE  ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008012820512...  ...   \n",
       "\n",
       "                                      133.245.254.55  \\\n",
       "                                               58270   \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333...   \n",
       "\n",
       "                                     131.137.243.202  \\\n",
       "                                               55055   \n",
       "0                                                 BE   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     216.116.245.163  \\\n",
       "                                               443     \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666...   \n",
       "\n",
       "                                      150.57.112.227  \\\n",
       "                                               59234   \n",
       "0                                                 BE   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      157.24.200.214  \\\n",
       "                                               443     \n",
       "0                                                 BE   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      118.101.243.35  \\\n",
       "                                               60296   \n",
       "0                                                 BE   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      150.57.154.156  \\\n",
       "                                               57659   \n",
       "0                                                 BE   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     131.137.220.107  \\\n",
       "                                               52687   \n",
       "0                                                 BE   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     131.137.243.202  \\\n",
       "                                               55108   \n",
       "0                                                 BE   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     131.137.251.245  \n",
       "                                               51412  \n",
       "0                                                 BE  \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "\n",
       "[3 rows x 5744 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFlow=pd.read_pickle('Flows.pkl')\n",
    "dataFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
